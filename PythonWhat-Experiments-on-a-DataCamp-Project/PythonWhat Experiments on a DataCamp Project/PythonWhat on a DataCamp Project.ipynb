{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my experiments with `pythonwhat` (A Python library to verify Python code submissions and auto-generate meaningful feedback messages) on my recently launched DataCamp Project - [Predicting Credit Card Approvals](https://www.datacamp.com/projects/558). The library is just incredible amazing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonwhat.test_exercise import prep_context\n",
    "from pythonwhat.local import setup_state\n",
    "\n",
    "_, ctxt = prep_context()\n",
    "globals().update(ctxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution code**:\n",
    "\n",
    "![](https://i.ibb.co/QFLsfYZ/carbon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the student code is correct and exactly identical to the solution code given above - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the student code and solution code files (.py)\n",
    "student_code = open('task_1_stu.py').read()\n",
    "solution_code = open('task_1_sol.py').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code all corect!\n"
     ]
    }
   ],
   "source": [
    "# Set up for process states\n",
    "setup_state(stu_code = student_code, \\\n",
    "            sol_code = solution_code)\n",
    "\n",
    "# SCT\n",
    "try:\n",
    "    Ex().check_function('pandas.read_csv')\\\n",
    "    .multi(\n",
    "        check_args('filepath_or_buffer').has_equal_value(),\n",
    "        check_args('header').has_equal_value())\n",
    "    Ex().check_function(\"cc_apps.head\")\n",
    "    print('Code all corect!')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in case the student submits code which does not follow the instructions properly - \n",
    "\n",
    "![](https://i.ibb.co/JjqKZpv/carbon-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check your call of `pd.read_csv()`. Did you specify the argument `header`?\n"
     ]
    }
   ],
   "source": [
    "student_code = open('task_1_stu_wrong.py').read()\n",
    "\n",
    "setup_state(stu_code = student_code, \\\n",
    "            sol_code = solution_code)\n",
    "\n",
    "# SCT\n",
    "try:\n",
    "    Ex().check_function('pandas.read_csv')\\\n",
    "    .multi(\n",
    "        check_args('filepath_or_buffer').has_equal_value(),\n",
    "        check_args('header').has_equal_value())\n",
    "    Ex().check_function(\"cc_apps.head\")\n",
    "    print('Code all corect!')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case, a student forgets calling the `head()` method - \n",
    "\n",
    "![](https://i.ibb.co/J7LLVNK/carbon-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you call `cc_apps.head()`?\n"
     ]
    }
   ],
   "source": [
    "student_code = open('task_1_stu_wrong2.py').read()\n",
    "\n",
    "setup_state(stu_code = student_code, \\\n",
    "            sol_code = solution_code)\n",
    "\n",
    "# SCT\n",
    "try:\n",
    "    Ex().check_function('pandas.read_csv')\\\n",
    "    .multi(\n",
    "        check_args('filepath_or_buffer').has_equal_value(),\n",
    "        check_args('header').has_equal_value())\n",
    "    Ex().check_function(\"cc_apps.head\")\n",
    "    print('Code all corect!')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution code**:\n",
    "\n",
    "![](https://i.ibb.co/gwTMcTJ/carbon-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of a correct submission - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import pandas as pd\n",
    "cc_apps = pd.read_csv('datasets/cc_approvals.data', header=None)\n",
    "cc_apps_description = cc_apps.describe()\n",
    "cc_apps_info = cc_apps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code all corect!\n"
     ]
    }
   ],
   "source": [
    "student_code = open('task_2_stu.py').read()\n",
    "solution_code = open('task_2_sol.py').read()\n",
    "\n",
    "setup_state(stu_code = student_code, \\\n",
    "            sol_code = solution_code)\n",
    "\n",
    "# SCT\n",
    "try:\n",
    "    Ex().check_object('cc_apps_description').has_equal_value()\n",
    "    Ex().check_function('cc_apps.describe')\n",
    "    Ex().check_object('cc_apps_info').has_equal_value()\n",
    "    Ex().check_function('cc_apps.info')\n",
    "    Ex().check_function(\"cc_apps.tail\")\n",
    "    print('Code all corect!')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of probable incorrectness - \n",
    "\n",
    "In the following case, a student if declares a wrong variable (`cc_apps_desc` instead of `cc_apps_description`): \n",
    "\n",
    "![](https://i.ibb.co/bBkf6tR/carbon-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you define the variable `cc_apps_description` without errors?\n"
     ]
    }
   ],
   "source": [
    "student_code = open('task_2_stu_wrong.py').read()\n",
    "setup_state(stu_code = student_code, \\\n",
    "            sol_code = solution_code)\n",
    "\n",
    "# SCT\n",
    "try:\n",
    "    Ex().check_object('cc_apps_description').has_equal_value()\n",
    "    Ex().check_function('cc_apps.describe')\n",
    "    Ex().check_object('cc_apps_info').has_equal_value()\n",
    "    Ex().check_function('cc_apps.info')\n",
    "    Ex().check_function(\"cc_apps.tail\")\n",
    "    print('Code all corect!')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution code**:\n",
    "\n",
    "![](https://i.ibb.co/XsjtPjy/carbon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now only cover the incorrect grounds. The main objective of Task-3 is to check if a student is able to properly identify the missing values in the dataset and replace them with `np.nan`. \n",
    "\n",
    "(The missing values in the dataset are present in form of `?`)\n",
    "\n",
    "So what happens if a student marks the missing values with `NaN` instead of `np.nan`? This is a fundamental error and it can significantly change the internal workings of the data-types. \n",
    "\n",
    "![](https://i.ibb.co/8M3QNzz/carbon-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main solution\n",
    "import numpy as np\n",
    "cc_apps = cc_apps.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you replacing the missing values with `np.nan`?\n"
     ]
    }
   ],
   "source": [
    "student_code = open('task_3_stu_wrong.py').read()\n",
    "solution_code = open('task_3_sol.py').read()\n",
    "\n",
    "setup_state(stu_code = student_code, \\\n",
    "            sol_code = solution_code)\n",
    "\n",
    "# SCT\n",
    "try:\n",
    "    Ex().check_object('cc_apps').has_equal_value()\n",
    "    print('Code all corect!')\n",
    "except Exception as e:\n",
    "    print('Are you replacing the missing values with `np.nan`?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution code**: \n",
    "\n",
    "![](https://i.ibb.co/hRdczNz/carbon-2.png)\n",
    "\n",
    "The aim of this task is to check if a student is able to correctly impute the missing values. What a student does not do it the way as instructed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main solution\n",
    "cc_apps.fillna(cc_apps.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check your call of `cc_apps.fillna()`. Did you correctly specify the argument `value`? Expected something different.\n"
     ]
    }
   ],
   "source": [
    "student_code = open('task_4_stu_wrong.py').read()\n",
    "solution_code = open('task_4_sol.py').read()\n",
    "\n",
    "setup_state(stu_code = student_code, \\\n",
    "            sol_code = solution_code)\n",
    "\n",
    "# SCT\n",
    "try:\n",
    "    Ex().check_function('cc_apps.fillna').multi(\n",
    "        check_args('value').has_equal_value(),\n",
    "        check_args('inplace').has_equal_value())\n",
    "    print('Code all corect!')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued till the rest of th tasks of the project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
